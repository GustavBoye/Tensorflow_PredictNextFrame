import os
import random
import matplotlib.pyplot as plt
import tensorflow as tf
from PIL import Image
import numpy as np

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print(tf.__version__)

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

print(tf.config.list_physical_devices('GPU'))


def load_images(folder_path):
    images = []
    image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))])
    for image_file in image_files:
        image_path = os.path.join(folder_path, image_file)
        image = Image.open(image_path)
        image = image.resize((64, 64))  # Resize for faster training
        image = np.array(image) / 255.0  # Normalize pixel values
        images.append(image)
    return np.array(images)


def create_dataset(images):
    batch_input_frames = []
    batch_output_frames = []

    start_index = 0

    for i in range(len(images)-5):
        start_index += 1
        input_frames = images[start_index:start_index + 4]  # Results in (4, 64, 64, 3)

        stacked_input_frames = np.concatenate(input_frames,
                                              axis=-1)  # Stack input frames along the last axis, results in (64, 64, 12)

        output_frame = images[start_index + 4]

        batch_input_frames.append(stacked_input_frames)
        batch_output_frames.append(output_frame)

    return np.array(batch_input_frames), np.array(batch_output_frames)

def create_dataset_vae(images):
    batch_frames = []

    start_index = 0

    for i in range(len(images)-6):
        start_index += 1
        input_frames = images[start_index]  # Results in (4, 64, 64, 3)

        batch_frames.append(input_frames)

    return np.array(batch_frames)



import tensorflow as tf


def build_model_predictor():
    inputs = tf.keras.layers.Input(shape=(64, 64, 12))

    # Encoder
    first = tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same')(inputs)
    first = tf.keras.layers.LeakyReLU()(first)

    conv1 = tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(first)
    conv1 = tf.keras.layers.GaussianNoise(0.1)(conv1)
    conv1 = tf.keras.layers.LeakyReLU()(conv1)
    conv1 = tf.keras.layers.BatchNormalization()(conv1)
    print(conv1.shape) # 32 32 32

    conv2 = tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(conv1)
    conv2 = tf.keras.layers.GaussianNoise(0.1)(conv2)
    conv2 = tf.keras.layers.LeakyReLU()(conv2)
    conv2 = tf.keras.layers.BatchNormalization()(conv2)

    conv2b = tf.keras.layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same')(conv2)
    conv2b = tf.keras.layers.GaussianNoise(0.1)(conv2b)
    conv2b = tf.keras.layers.LeakyReLU()(conv2b)
    conv2b = tf.keras.layers.BatchNormalization()(conv2b)+conv2
    print(conv2.shape) # 16 16 64

    conv3 = tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same')(conv2b)
    conv3 = tf.keras.layers.GaussianNoise(0.1)(conv3)
    conv3 = tf.keras.layers.LeakyReLU()(conv3)
    conv3 = tf.keras.layers.BatchNormalization()(conv3)
    print(conv3.shape) # 8 8 128

    # Decoder
    up1 = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(conv3)
    up1 = tf.keras.layers.LeakyReLU()(up1)
    up1 = tf.keras.layers.BatchNormalization()(up1)
    merge1 = tf.keras.layers.concatenate([up1, conv2], axis=3)
    print(merge1.shape) # 16 16 64

    up2 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(merge1)
    up2 = tf.keras.layers.LeakyReLU()(up2)
    up2 = tf.keras.layers.BatchNormalization()(up2)
    merge2 = tf.keras.layers.concatenate([up2, conv1], axis=3)
    print(conv2.shape) # 32 32 32

    up3 = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(merge2)
    up3 = tf.keras.layers.LeakyReLU()(up3)
    up3 = tf.keras.layers.BatchNormalization()(up3)
    merge3 = tf.keras.layers.concatenate([up3, first], axis=3)
    print(merge3.shape) # 64 64 16

    # Output layer
    outputs = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='relu')(merge3)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)

    model.compile(optimizer='adam',
                  loss='mse',  # Change loss function to mean squared error for regression
                  metrics=['accuracy'])

    return model

def build_model_vae():
    inputs = tf.keras.layers.Input(shape=(64, 64, 3))

    # Encoder

    conv1 = tf.keras.layers.GaussianNoise(0.1)(inputs)
    conv1 = tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(conv1)
    conv1 = tf.keras.layers.LeakyReLU()(conv1)
    conv1 = tf.keras.layers.BatchNormalization()(conv1)
    print(conv1.shape) # 32 32 64

    conv2 = tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(conv1)
    conv2 = tf.keras.layers.LeakyReLU()(conv2)
    conv2 = tf.keras.layers.BatchNormalization()(conv2)
    print(conv2.shape) # 16 16 128

    conv2b = tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same')(conv2)
    conv2b = tf.keras.layers.LeakyReLU()(conv2b)
    conv2b = tf.keras.layers.BatchNormalization()(conv2b)
    print(conv2.shape) # 8 8 256

    conv3 = tf.keras.layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same')(conv2b)
    conv3 = tf.keras.layers.LeakyReLU()(conv3)
    conv3 = tf.keras.layers.BatchNormalization()(conv3)

    # Decoder
    up1 = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(conv3)
    up1 = tf.keras.layers.LeakyReLU()(up1)
    up1 = tf.keras.layers.BatchNormalization()(up1)

    up2 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(up1)
    up2 = tf.keras.layers.LeakyReLU()(up2)
    up2 = tf.keras.layers.BatchNormalization()(up2)

    up3 = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(up2)
    up3 = tf.keras.layers.LeakyReLU()(up3)
    up3 = tf.keras.layers.BatchNormalization()(up3)

    # Output layer
    outputs = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='relu')(up3)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)

    model.compile(optimizer='adam',
                  loss='mse',  # Change loss function to mean squared error for regression
                  metrics=['accuracy'])

    return model



# Replace 'folder_path' with the path to your folder containing images
folder_path = 'C:/Users/G_Cha/Videos/ShortWater'
images = load_images(folder_path)


model_predictor = build_model_predictor()
model_vae = build_model_vae()
#model_predictor = tf.keras.models.load_model('./checkpoints/predictor.keras')
#model_vae = tf.keras.models.load_model('./checkpoints/model_vae.keras')

# Train the model using batches
train_x, train_y = create_dataset(images)
train_x_vae = create_dataset_vae(images)


print(train_x_vae.shape)

#model_predictor.load_weights('./checkpoints/model.weights.h5')
#model_vae.load_weights('./checkpoints/model_vae.weights.h5')



while True:
    model_predictor.fit(train_x, train_y, epochs=100, batch_size=128)

    model_vae.fit(train_x_vae, train_x_vae, epochs=100, batch_size=64)

    model_predictor.save('./checkpoints/predictor.keras')
    model_vae.save('./checkpoints/model_vae.keras')


    def add_stack(stack, image):

        print(stack.shape) #(1, 64, 64, 12)
        print(image.shape) #(1, 64, 64, 3)


        stacked = np.concatenate([stack, image], axis=-1)
        print(stacked.shape)

        stacked_stripped = stacked[:, :, :, 3:]
        print(stacked_stripped.shape)


        return stacked_stripped




    starting_point = train_x[0]
    starting_point = np.expand_dims(starting_point, axis=0)
    print(f"starting point shape: {starting_point.shape}")


    for i in range(30):

        predicted_image = model_predictor.predict(starting_point)
        print(predicted_image.shape)
        predicted_image = np.clip(predicted_image, 0, 1)
        print(predicted_image.shape)
        save_path = os.path.join("C:/Users/G_Cha/Videos/Predicted", f"predicted_image_{i}.png")
        n = predicted_image[0]
        plt.imsave(save_path, n)  # Save the image using matplotlib

        starting_point = add_stack(starting_point, predicted_image)
        print(f"starting point shape: {starting_point.shape}")

    for i in range(30):

        predicted_image = model_predictor.predict(starting_point)
        print(predicted_image.shape)
        predicted_image = np.clip(predicted_image, 0, 1)
        print(predicted_image.shape)
        predicted_image = model_vae(predicted_image)
        predicted_image = np.clip(predicted_image, 0, 1)
        print(predicted_image.shape)
        save_path = os.path.join("C:/Users/G_Cha/Videos/Predicted", f"predicted_image_using_vae_{i}.png")
        n = predicted_image[0]
        plt.imsave(save_path, n)  # Save the image using matplotlib

        starting_point = add_stack(starting_point, predicted_image)
        print(f"starting point shape: {starting_point.shape}")
