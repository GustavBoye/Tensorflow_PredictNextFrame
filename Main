import os
import random
import matplotlib.pyplot as plt
import tensorflow as tf
from PIL import Image
import numpy as np

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print(tf.__version__)

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

print(tf.config.list_physical_devices('GPU'))


def load_images(folder_path):
    images = []
    image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))])
    for image_file in image_files:
        image_path = os.path.join(folder_path, image_file)
        image = Image.open(image_path)
        image = image.resize((64, 64))  # Resize for faster training
        image = np.array(image) / 255.0  # Normalize pixel values
        images.append(image)
    return np.array(images)


def create_dataset(images):
    batch_input_frames = []
    batch_output_frames = []

    start_index = 0

    for i in range(len(images)-5):
        start_index += 1
        input_frames = images[start_index:start_index + 4]  # Results in (4, 64, 64, 3)

        stacked_input_frames = np.concatenate(input_frames,
                                              axis=-1)  # Stack input frames along the last axis, results in (64, 64, 12)

        output_frame = images[start_index + 4]

        batch_input_frames.append(stacked_input_frames)
        batch_output_frames.append(output_frame)

    return np.array(batch_input_frames), np.array(batch_output_frames)

def create_dataset_vae(images):
    batch_frames = []

    start_index = 0

    for i in range(len(images)-6):
        start_index += 1
        input_frames = images[start_index]  # Results in (4, 64, 64, 3)

        batch_frames.append(input_frames)

    return np.array(batch_frames)



import tensorflow as tf


def encoder_block(inputs, filters):
    conv = tf.keras.layers.Conv2D(filters, (3,3), strides=(2,2), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(inputs)
    conv = tf.keras.layers.BatchNormalization()(conv)
    conv = tf.keras.layers.LeakyReLU()(conv)
    return conv

def decoder_block(inputs, filters, merge_with):
    #noise = tf.keras.layers.GaussianNoise(0.05)(inputs)
    upsample = tf.keras.layers.Conv2DTranspose(filters,(3,3), strides=(2,2), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(inputs)
    upsample = tf.keras.layers.BatchNormalization()(upsample)
    upsample = tf.keras.layers.LeakyReLU()(upsample)

    upsample = tf.keras.layers.concatenate([upsample, merge_with], axis=3)
    return upsample


def skip_block(inputs, filters, merge_with):
    upsample = tf.keras.layers.Conv2DTranspose(filters,(1,1), strides=(1,1), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(inputs)
    upsample = tf.keras.layers.BatchNormalization()(upsample)
    upsample = tf.keras.layers.LeakyReLU()(upsample)

    upsample = tf.keras.layers.concatenate([upsample, merge_with], axis=3)
    return upsample

def build_generator():
    inputs = tf.keras.layers.Input(shape=(64, 64, 12))

    inputs = tf.keras.layers.GaussianNoise(0.1)(inputs)

    # Encoder
    conv1 = encoder_block(inputs, 32) #32, 32
    conv1s = skip_block(conv1, 32, conv1)

    conv2 = encoder_block(conv1s, 64) #16, 16
    conv2s = skip_block(conv2, 64, conv2)

    conv3 = encoder_block(conv2s, 128) #8, 8

    # Decoder
    up1 = decoder_block(conv3, 128, conv2) #16, 16

    up2 = decoder_block(up1, 64, conv1) #32, 32
    up2s = skip_block(up2, 64, up2)

    up3 = decoder_block(up2s, 32, inputs) #64, 64
    up3s = skip_block(up3, 32, up3)

    # Output layer
    outputs = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='relu')(up3s)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)

    return model


# Replace 'folder_path' with the path to your folder containing images
folder_path = 'C:/Users/G_Cha/Videos/ShortWater'
images = load_images(folder_path)


generator = build_generator()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
generator.compile(optimizer=optimizer, loss='mse')

#generator = tf.keras.models.load_model('./checkpoints/gen.keras')

# Train the model using batches
train_x, train_y = create_dataset(images)
train_x_vae = create_dataset_vae(images)


print(train_x_vae.shape)

#model_predictor.load_weights('./checkpoints/model.weights.h5')
#model_vae.load_weights('./checkpoints/model_vae.weights.h5')



while True:
    generator.fit(train_x, train_y, epochs=150, batch_size=64, shuffle=True)


    generator.save('./checkpoints/gen.keras')



    def add_stack(stack, image):

        print(stack.shape) #(1, 64, 64, 12)
        print(image.shape) #(1, 64, 64, 3)


        stacked = np.concatenate([stack, image], axis=-1)
        print(stacked.shape)

        stacked_stripped = stacked[:, :, :, 3:]
        print(stacked_stripped.shape)


        return stacked_stripped




    starting_point = train_x[0]
    starting_point = np.expand_dims(starting_point, axis=0)
    print(f"starting point shape: {starting_point.shape}")


    for i in range(120):

        predicted_image = generator.predict(starting_point)
        print(predicted_image.shape)
        predicted_image = np.clip(predicted_image, 0, 1)
        print(predicted_image.shape)
        save_path = os.path.join("C:/Users/G_Cha/Videos/Predicted", f"predicted_image_{i}.png")
        n = predicted_image[0]
        plt.imsave(save_path, n)  # Save the image using matplotlib

        starting_point = add_stack(starting_point, predicted_image)
        print(f"starting point shape: {starting_point.shape}")
