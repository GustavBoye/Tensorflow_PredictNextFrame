import os
import random
import matplotlib.pyplot as plt
import tensorflow as tf
from PIL import Image
import numpy as np

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print(tf.__version__)

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

print(tf.config.list_physical_devices('GPU'))


def load_images(folder_path):
    images = []
    image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))])
    for image_file in image_files:
        image_path = os.path.join(folder_path, image_file)
        image = Image.open(image_path)
        image = image.resize((64, 64))  # Resize for faster training
        image = np.array(image) / 255.0  # Normalize pixel values
        images.append(image)
    return np.array(images)


def create_dataset(images):
    batch_input_frames = []
    batch_output_frames = []

    start_index = 0

    for i in range(len(images)-5):
        start_index += 1
        input_frames = images[start_index:start_index + 4]  # Results in (4, 64, 64, 3)

        stacked_input_frames = np.concatenate(input_frames,
                                              axis=-1)  # Stack input frames along the last axis, results in (64, 64, 12)

        output_frame = images[start_index + 4]

        batch_input_frames.append(stacked_input_frames)
        batch_output_frames.append(output_frame)

    return np.array(batch_input_frames), np.array(batch_output_frames)


import tensorflow as tf


def build_model():
    inputs = tf.keras.layers.Input(shape=(64, 64, 12))

    # Encoder
    first = tf.keras.layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same')(inputs)

    conv1 = tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(first)
    conv1 = tf.keras.layers.LeakyReLU()(conv1)
    conv1 = tf.keras.layers.BatchNormalization()(conv1)
    print(conv1.shape) # 32 32 32

    conv2 = tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(conv1)
    conv2 = tf.keras.layers.LeakyReLU()(conv2)
    conv2 = tf.keras.layers.BatchNormalization()(conv2)
    print(conv2.shape) # 16 16 64

    conv3 = tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(conv2)
    conv3 = tf.keras.layers.LeakyReLU()(conv3)
    conv3 = tf.keras.layers.BatchNormalization()(conv3)
    print(conv3.shape) # 8 8 128

    # Decoder
    up1 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(conv3)
    up1 = tf.keras.layers.LeakyReLU()(up1)
    up1 = tf.keras.layers.BatchNormalization()(up1)
    merge1 = tf.keras.layers.concatenate([up1, conv2], axis=3)
    print(merge1.shape) # 16 16 64

    up2 = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(merge1)
    up2 = tf.keras.layers.LeakyReLU()(up2)
    up2 = tf.keras.layers.BatchNormalization()(up2)
    merge2 = tf.keras.layers.concatenate([up2, conv1], axis=3)
    print(conv2.shape) # 32 32 32

    up3 = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(merge2)
    up3 = tf.keras.layers.LeakyReLU()(up3)
    up3 = tf.keras.layers.BatchNormalization()(up3)
    merge3 = tf.keras.layers.concatenate([up3, first], axis=3)
    print(merge3.shape) # 64 64 16

    # Output layer
    outputs = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='relu')(merge3)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)

    model.compile(optimizer='adam',
                  loss='mse',  # Change loss function to mean squared error for regression
                  metrics=['accuracy'])

    return model




# Replace 'folder_path' with the path to your folder containing images
folder_path = 'C:/Users/G_Cha/Videos/ShortWater'
images = load_images(folder_path)


model = build_model()

# Train the model using batches
train_x, train_y = create_dataset(images)

print(train_x.shape)

model.load_weights('./checkpoints/model.weights.h5')

model.fit(train_x, train_y, epochs=200, batch_size=32)

model.save_weights('./checkpoints/model.weights.h5')


def add_stack(stack, image):

    print(stack.shape) #(1, 64, 64, 12)
    print(image.shape) #(1, 64, 64, 3)


    stacked = np.concatenate([stack, image], axis=-1)
    print(stacked.shape)

    stacked_stripped = stacked[:, :, :, 3:]
    print(stacked_stripped.shape)


    return stacked_stripped




starting_point = train_x[0:2]
print(f"starting point shape: {starting_point.shape}")


for i in range(20):

    predicted_image = model.predict(starting_point)
    predicted_image = np.clip(predicted_image, 0, 1)
    save_path = os.path.join("C:/Users/G_Cha/Videos/Predicted", f"predicted_image_{i}.png")
    plt.imsave(save_path, predicted_image[0])  # Save the image using matplotlib

    starting_point = add_stack(starting_point, predicted_image)
    print(f"starting point shape: {starting_point.shape}")
